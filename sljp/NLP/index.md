---
layout: copy
title: NLP自然语言处理学习资料库
date: '2019-09-18 17:15:15 +0800'
permalink: /sljp/NLP
published: True
---
<br><br><br>
》》》示例项目《《《<br>
<p><strong>自动对联及作诗机</strong><br>
<a href="https://mp.weixin.qq.com/s/A6FMzXS0W7jyTMuyCgzJhw" target="_blank" rel="noopener">风云三尺剑，花鸟一床书---对联数据集和自动对联机器人</a><br>
<a href="https://mp.weixin.qq.com/s/VSPPEVcihLUcJMmh7h3hgA" target="_blank" rel="noopener">自动对联活动获奖结果以及机器对联赏析</a><br>
<a href="https://mp.weixin.qq.com/s/w8e0TixjbqvKXnZksL32tQ" target="_blank" rel="noopener">"自动作诗机"上线，代码和数据都是公开的</a></p>
<p><strong>腾讯词向量和相似词、相似度、词语游戏系列</strong><br>
<a href="https://mp.weixin.qq.com/s/UwPwW8JzWVQrVwbPy9321g" target="_blank" rel="noopener">相似词查询：玩转腾讯 AI Lab 中文词向量</a><br>
<a href="https://mp.weixin.qq.com/s/Q533WJ7Kwtehwm8aLuKbDA" target="_blank" rel="noopener">玩转腾讯词向量：词语相似度计算和在线查询</a><br>
<a href="https://mp.weixin.qq.com/s/oboRxo9k4am4AUGmR5YG9Q" target="_blank" rel="noopener">腾讯词向量实战：通过Annoy进行索引和快速查询</a><br>
<a href="https://mp.weixin.qq.com/s/cMMVCFcBoDfcTZXhRty63w" target="_blank" rel="noopener">玩转腾讯词向量：Game of Words（词语的加减游戏）</a><br>
<a href="https://mp.weixin.qq.com/s/8BVerIljzZHX3KFnYedDgg" target="_blank" rel="noopener">词向量游戏：梅西-阿根廷+葡萄牙=?</a></p>
<p><strong>NLP相关工具及在线测试（公众号对话测试）</strong><br>
<a href="https://mp.weixin.qq.com/s/Sy2hukGVk-7QQY_YNQ10kw" target="_blank" rel="noopener">五款中文分词工具在线PK: Jieba, SnowNLP, PkuSeg, THULAC, HanLP</a><br>
<a href="https://mp.weixin.qq.com/s/YvpVumIdBDA9vBjGeLoPZA" target="_blank" rel="noopener">中文分词工具在线PK新增：FoolNLTK、LTP、StanfordCoreNLP</a><br>
<a href="https://mp.weixin.qq.com/s/rFCBnExyZVHI-SwrSj7pmA" target="_blank" rel="noopener">Python中文分词工具大合集：安装、使用和测试</a><br>
<a href="https://mp.weixin.qq.com/s/9ArR_D2Xu2IjKtn9xU0ycA" target="_blank" rel="noopener">中文分词工具评估：chinese-segmentation-evaluation</a><br>
<a href="https://mp.weixin.qq.com/s/uATfclTlXqAnkp4ep8ZRMQ" target="_blank" rel="noopener">中文分词文章索引和分词数据资源分享</a><br>
<a href="https://mp.weixin.qq.com/s/vRGhSogb6Kc19eicEchylQ" target="_blank" rel="noopener">自然语言理解太难了之中文分词八级测试</a><br>
<a href="https://mp.weixin.qq.com/s/LwtQVg9p_VBzwA_2uvX8GA" target="_blank" rel="noopener">八款中文词性标注工具使用及在线测试</a><br>
<a href="https://mp.weixin.qq.com/s/pOGdatZK5Z7uxmveHAX4_Q" target="_blank" rel="noopener">百度深度学习中文词法分析工具LAC试用之旅</a><br>
<a href="https://mp.weixin.qq.com/s/Vj0IKHWD_aXto8NE8alz8g" target="_blank" rel="noopener">来，试试百度的深度学习情感分析工具</a><br>
<a href="https://mp.weixin.qq.com/s/2y-TshJqNHW5ixzjbtdekg" target="_blank" rel="noopener">AINLP公众号新增SnowNLP情感分析模块</a></p>
<p><strong>聊天机器人相关</strong><br>
<a href="https://mp.weixin.qq.com/s/B0ilgxGnLPMYDny1FYmWHw" target="_blank" rel="noopener">一行Python代码实现夸夸聊天机器人</a><br>
<a href="https://mp.weixin.qq.com/s/pUhugd5WTru32M1l6Qrxzg" target="_blank" rel="noopener">为了夸夸聊天机器人，爬了一份夸夸语料库</a><br>
<a href="https://mp.weixin.qq.com/s/NO2M8_VD29uCaUuTrkzfyA" target="_blank" rel="noopener">夸夸聊天机器人升级：从随机到准个性化</a><br>
<a href="https://mp.weixin.qq.com/s/fSzWY835t1bgZsv901S_FA" target="_blank" rel="noopener">来，试试语音（识别）聊天（机器人）</a><br>
<a href="https://mp.weixin.qq.com/s/Fe1WJUaaXpe4gERZFmhUIw">来，试试成语接龙</a></p>

<br><br>

》》》NLP教程《《《
<br>
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <!-- flowchart 箭头图标 勿删 -->
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                                            <h1 id="nlp"><a name="t0"></a>NLP</h1>

<p>自然语言处理（Natural Language Processing）是深度学习的主要应用领域之一。</p>



<h2 id="教程"><a name="t1"></a>教程</h2>

<p><a href="http://cs224d.stanford.edu/" rel="nofollow" data-token="cd8a95abdb6f133c70acb5f546cef206">http://cs224d.stanford.edu/</a></p>

<p>CS224d: Deep Learning for Natural Language Processing</p>

<p><a href="http://web.stanford.edu/class/cs224n/syllabus.html" rel="nofollow" data-token="a773068ddd478cacb2b5edb962928d67">http://web.stanford.edu/class/cs224n/syllabus.html</a></p>

<p>cs224d课程的课件</p>

<p><a href="http://demo.clab.cs.cmu.edu/NLP/" rel="nofollow" data-token="57e9208c3c8a22c9fe382dff94e986a6">http://demo.clab.cs.cmu.edu/NLP/</a></p>

<p>CMU的NLP教程。该网页下方还有美国其他高校的NLP课程的链接。</p>

<p><a href="http://ccl.pku.edu.cn/alcourse/nlp/" rel="nofollow" data-token="34d3a62561ac187c07cfb50a6aafad09">http://ccl.pku.edu.cn/alcourse/nlp/</a></p>

<p>北京大学的NLP教程，特色：中文处理。缺点：传统方法居多，深度学习未涉及。</p>

<p><a href="http://www.cs.columbia.edu/~cs4705/" rel="nofollow" data-token="4193175f3e0755b2de3be4bbc108d824">http://www.cs.columbia.edu/~cs4705/</a></p>

<p>COMS W4705: Natural Language Processing</p>

<p><a href="https://mp.weixin.qq.com/s/TSc4E8lKwgc-EvzP8OlJeg" rel="nofollow" data-token="ba8c3a4f5a6d02501f78054e92281edc">https://mp.weixin.qq.com/s/TSc4E8lKwgc-EvzP8OlJeg</a></p>

<p>初学者如何查阅自然语言处理（NLP）领域学术资料</p>

<p><a href="https://zhuanlan.zhihu.com/kb-qa" rel="nofollow" data-token="5fc1f34f40c1bf27595b7fdc53e25240">https://zhuanlan.zhihu.com/kb-qa</a></p>

<p>揭开知识库问答KB-QA的面纱（知识图谱方面的系列专栏）</p>

<p><a href="http://web.stanford.edu/~jurafsky/slp3/ed3book.pdf" rel="nofollow" data-token="2df15746a23814ce583bbdb651d2eb67">http://web.stanford.edu/~jurafsky/slp3/ed3book.pdf</a></p>

<p>《语音与语言处理》第三版，NLP和语音合成方面的专著</p>

<p><a href="https://mp.weixin.qq.com/s/5KhTWdOk-b84DXmoVr68-A" rel="nofollow" data-token="5db70062aeb25a495c5518f20cd395c4">https://mp.weixin.qq.com/s/5KhTWdOk-b84DXmoVr68-A</a></p>

<p>CIPS ATT 2017 文本分析和自然语言课程PPT</p>

<p><a href="http://phontron.com/class/nn4nlp2017/assets/slides/" rel="nofollow" data-token="5a793eb216150ffab402abe72f8e90b6">http://phontron.com/class/nn4nlp2017/assets/slides/</a></p>

<p>CMU NN for NLP</p>

<p><a href="http://phontron.com/class/mtandseq2seq2017/" rel="nofollow" data-token="944288f1daf38cec7d7a4abc747b218d">http://phontron.com/class/mtandseq2seq2017/</a></p>

<p>CMU Machine Translation and Sequence to Sequence Models</p>

<p><a href="https://github.com/oxford-cs-deepnlp-2017/lectures" rel="nofollow" data-token="d624ec41ef4839ca42a280fdff5d5111">https://github.com/oxford-cs-deepnlp-2017/lectures</a></p>

<p>Oxford Deep NLP 2017 course</p>



<h2 id="书籍"><a name="t2"></a>书籍</h2>

<p><a href="http://ccl.pku.edu.cn/alcourse/nlp/LectureNotes/Natural%20Language%20Processing%20with%20Python.pdf" rel="nofollow" data-token="9ba6b0f16c13f7575aef3ec68f22f494">http://ccl.pku.edu.cn/alcourse/nlp/LectureNotes/Natural%20Language%20Processing%20with%20Python.pdf</a></p>

<p>《Natural Language Processing with Python》，Steven Bird、Ewan Klein、Edward Loper著。这本书的作者们创建了著名的NLTK工具库。</p>

<blockquote>
  <p>注：Steven Bird，爱丁堡大学博士，墨尔本大学副教授。 <br>
  <a href="http://www.stevenbird.net/about.html" rel="nofollow" data-token="47b45d2653b1017185ab7c2009624619">http://www.stevenbird.net/about.html</a></p>
  
  <p>Ewan Klein，苏格兰人，哥伦比亚大学博士（1978年），爱丁堡大学教授。</p>
  
  <p>Edward Loper，宾夕法尼亚大学博士。</p>
</blockquote>

<p><a href="https://mp.weixin.qq.com/s/0HmsMytif3INqAX1Si5ukA" rel="nofollow" data-token="b048648df427d6e4ea028e2973d62817">https://mp.weixin.qq.com/s/0HmsMytif3INqAX1Si5ukA</a></p>

<p>推荐5本经典自然语言处理书籍</p>



<h2 id="网站"><a name="t3"></a>网站</h2>

<p><a href="http://www.52nlp.cn/" rel="nofollow" data-token="6feb4174416208905522144e0c94ec86">http://www.52nlp.cn/</a></p>

<p>一个自然语言处理爱好者的群体博客。包括52nlp、rickjin、liwei等国内外华人大牛。</p>

<p><a href="http://www.shareditor.com/bloglistbytag/?tagname=%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%81%9A%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA" rel="nofollow" data-token="3f431df9d60fa59e82ee5e76d331113b">http://www.shareditor.com/bloglistbytag/?tagname=%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E5%81%9A%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA</a></p>

<p>实战课程：自己动手做聊天机器人</p>

<p><a href="http://www.icst.pku.edu.cn/lcwm/" rel="nofollow" data-token="1e34ae86560d92a786aefdd95a164a72">http://www.icst.pku.edu.cn/lcwm/</a></p>

<p>北京大学计算机科学技术研究所语言计算与互联网挖掘研究室</p>

<p><a href="https://github.com/rockingdingo/deepnlp" rel="nofollow" data-token="0c02acaae0aafbf542efff1df09bdf66">https://github.com/rockingdingo/deepnlp</a></p>

<p>NLP深度学习方面的代码库</p>

<p><a href="https://liweinlp.com/" rel="nofollow" data-token="7d8ba56ae914367f6e88c962cd5a2897">https://liweinlp.com/</a></p>

<p>NLP专家李维的blog</p>

<p><a href="http://www.shuang0420.com/" rel="nofollow" data-token="74304f0241ca6dd9401871ed7e3c292f">http://www.shuang0420.com/</a></p>

<p>一个NLP方面的blog</p>

<p><a href="http://www.cnblogs.com/Determined22/" rel="nofollow" data-token="df964c1008677c3b678b2c634658397e">http://www.cnblogs.com/Determined22/</a></p>

<p>一个DL+ML+NLP的blog</p>

<p><a href="http://www.cnblogs.com/robert-dlut/" rel="nofollow" data-token="08c9b5d21fb85eb80e0494a5cf05af1e">http://www.cnblogs.com/robert-dlut/</a></p>

<p>一个NLP方面的blog</p>

<p>blog.csdn.net/hellonlp/</p>

<p>一个NLP方面的blog</p>



<h2 id="工具"><a name="t4"></a>工具</h2>



<h3 id="natural-language-toolkitnltk"><a name="t5"></a>Natural Language Toolkit(NLTK)</h3>

<p>官网：</p>

<p><a href="http://www.nltk.org/" rel="nofollow" data-token="955b940f4b46e407e5fccb882f9bb0d1">http://www.nltk.org/</a></p>

<p>可使用nltk.download()下载相关nltk官方提供的各种资源。</p>

<p>参考：</p>

<p><a href="http://www.cnblogs.com/baiboy/p/nltk3.html" rel="nofollow" data-token="44e87d76714ed1db604e39ed214a09d5">http://www.cnblogs.com/baiboy/p/nltk3.html</a></p>



<h3 id="opennlp"><a name="t6"></a>OpenNLP</h3>

<p><a href="http://opennlp.apache.org/" rel="nofollow" data-token="7834e47962141824f5e251645560df61">http://opennlp.apache.org/</a></p>



<h3 id="fudannlp"><a name="t7"></a>FudanNLP</h3>

<p><a href="https://github.com/FudanNLP/fnlp" rel="nofollow" data-token="7c407fe602695a352561ed4e30c200b1">https://github.com/FudanNLP/fnlp</a></p>



<h3 id="stanford-corenlp"><a name="t8"></a>Stanford CoreNLP</h3>

<p><a href="http://stanfordnlp.github.io/CoreNLP/" rel="nofollow" data-token="d9a2cfe51095c183673f2b77e32b9a21">http://stanfordnlp.github.io/CoreNLP/</a></p>



<h3 id="thuctc"><a name="t9"></a>THUCTC</h3>

<p>THUCTC(THU Chinese Text Classification)是由清华大学自然语言处理实验室推出的中文文本分类工具包。</p>

<p><a href="http://thuctc.thunlp.org/" rel="nofollow" data-token="f9201d11375340a80fc65f4768077f2f">http://thuctc.thunlp.org/</a></p>



<h3 id="gensim"><a name="t10"></a>gensim</h3>

<p>gensim是Python语言的计算文本相似度的程序包。</p>

<p><a href="http://radimrehurek.com/gensim/index.html" rel="nofollow" data-token="8db0d6bc2b5082eb5057555804a0f31e">http://radimrehurek.com/gensim/index.html</a></p>

<p><code>pip install --upgrade gensim</code></p>

<p>GitHub：</p>

<p><a href="https://github.com/RaRe-Technologies/gensim" rel="nofollow" data-token="a3e57db617177e9124d55dd148281c61">https://github.com/RaRe-Technologies/gensim</a></p>

<p>参考：</p>

<p><a href="http://www.open-open.com/lib/view/open1444351655682.html" rel="nofollow" data-token="960ef55e162406a41919250acabebbb3">http://www.open-open.com/lib/view/open1444351655682.html</a></p>

<p>情感分析的新方法——基于Word2Vec/Doc2Vec/Python</p>

<p><a href="http://blog.csdn.net/Star_Bob/article/details/47808499" rel="nofollow" data-token="83398afce92e89ba4a80f84e6bbb754c">http://blog.csdn.net/Star_Bob/article/details/47808499</a></p>

<p>Gensim Word2vec使用教程</p>



<h3 id="glove"><a name="t11"></a>GloVe</h3>

<p>GloVe:Global Vectors for Word Representation</p>

<p><a href="https://nlp.stanford.edu/projects/glove/" rel="nofollow" data-token="afcced6b1b70d45da2b86661ad17f311">https://nlp.stanford.edu/projects/glove/</a></p>



<h3 id="textsum"><a name="t12"></a>textsum</h3>

<p>textsum是一个基于深度学习的文本自动摘要工具。</p>

<p>代码：</p>

<p><a href="https://github.com/tensorflow/models/tree/master/textsum" rel="nofollow" data-token="6e8170fe0ed03ebbc4bbc62882eb46bd">https://github.com/tensorflow/models/tree/master/textsum</a></p>

<p>参考：</p>

<p><a href="http://www.jiqizhixin.com/article/1449" rel="nofollow" data-token="2f9db0cac3565c6a2f817c0126ff085d">http://www.jiqizhixin.com/article/1449</a></p>

<p>谷歌开源新的TensorFlow文本自动摘要代码</p>

<p><a href="http://blog.csdn.net/tensorflowshizhan/article/details/69230070" rel="nofollow" data-token="005e0c9615fa8b29498773078319e948">http://blog.csdn.net/tensorflowshizhan/article/details/69230070</a></p>

<p>TensorFlow文本摘要生成 - 基于注意力的序列到序列模型</p>



<h3 id="jieba"><a name="t13"></a>jieba</h3>

<p><a href="https://github.com/fxsjy/jieba" rel="nofollow" data-token="14ffdd1e7c70cb914aa87337acfcaa92">https://github.com/fxsjy/jieba</a></p>



<h3 id="nlpir"><a name="t14"></a>NLPIR</h3>

<p>NLPIR汉语分词系统(又名ICTCLAS2013)，是中科院张华平博士的作品。官网：</p>

<p><a href="http://ictclas.nlpir.org/" rel="nofollow" data-token="66147f11cd030dded3e77aa35687df8d">http://ictclas.nlpir.org/</a></p>

<p>参考：</p>

<p><a href="http://ictclas.nlpir.org/nlpir/" rel="nofollow" data-token="8d8286b4e62e07e241abd202c80de67f">http://ictclas.nlpir.org/nlpir/</a></p>

<p>这个网页对于NLP的大多数功能进行了可视化的展示。NLP入门必看。</p>



<h3 id="snownlp"><a name="t15"></a>snownlp</h3>

<p><a href="https://github.com/isnowfy/snownlp" rel="nofollow" data-token="4073135c6132f8e8a3ee0ce2783ab114">https://github.com/isnowfy/snownlp</a></p>



<h3 id="hanlp"><a name="t16"></a>HanLP</h3>

<p>HanLP是一个目前留学日本的中国学生的作品。</p>

<p>官网：</p>

<p><a href="http://hanlp.linrunsoft.com/" rel="nofollow" data-token="d7aed03c5e3ef0710871aba983fa0177">http://hanlp.linrunsoft.com/</a></p>

<p>作者blog：</p>

<p><a href="http://www.hankcs.com/" rel="nofollow" data-token="9bdf6ef53a096340a64b6ba7e3f0b12f">http://www.hankcs.com/</a></p>

<p>Github：</p>

<p><a href="https://github.com/hankcs/HanLP/" rel="nofollow" data-token="5e436f0562ea2df46e9231e12524e024">https://github.com/hankcs/HanLP/</a></p>

<p>从作者的名气来说，HanLP无疑是最低的，性能也不见得有多好。然而对于初学者来说，这却是最适合的工具。这主要体现在以下几个方面：</p>

<p>1.中文处理能力。NLTK和OpenNLP对中文支持非常差，这里不光是中文分词的问题，有些NLP算法需要一定的语言模型数据，但浏览NLTK官方的模型库，基本找不到中文模型数据。</p>

<p>2.jieba、IK之类的功能太单一，多数局限在中文分词方面领域。gensim、THUCTC专注于NLP的某一方面，也不是通用工具。</p>

<p>3.NLPIR和Stanford CoreNLP算是功能最强的工具包了。前者的问题在于收费不开源，后者的问题在于缺少中文文档。FudanNLP的相关文档较少，文档友好度不如HanLP。</p>

<p>4.HanLP在主页上提供了相关算法的blog，便于初学者快速掌握相关概念。其词典是明文发布，便于用户修改。HanLP执行时，会将明文词典以特定结构缓存，以提高执行效率。</p>

<blockquote>
  <p>注：不要以为中文有分词问题，就比别的语言复杂，英文还有词根问题呢。。。每种语言都不简单。</p>
</blockquote>



<h2 id="allennlp"><a name="t17"></a>AllenNLP</h2>

<p>AllenNLP是Allen AI实验室的作品，采用深度学习技术，基于PyTorch开发。</p>

<p>官网：</p>

<p><a href="http://allennlp.org/" rel="nofollow" data-token="58fa643a16d4c04c10b649337e225777">http://allennlp.org/</a></p>

<p>Allen AI实验室由微软联合创始人Paul G. Allen投资创立。</p>

<p>官网：</p>

<p><a href="http://allenai.org/" rel="nofollow" data-token="23bf9db973a5497e95db5e195a4a7aba">http://allenai.org/</a></p>



<h3 id="其他"><a name="t18"></a>其他</h3>

<p><a href="https://github.com/mozillazg/python-pinyin" rel="nofollow" data-token="a339bee8fa1d98d7bbc85b4b1df0990d">https://github.com/mozillazg/python-pinyin</a></p>

<p>python版的汉字转拼音软件</p>

<p><a href="https://github.com/ysc/word" rel="nofollow" data-token="f0b8ef7ea15bdf5be2a32bf3def86756">https://github.com/ysc/word</a></p>

<p>Java分布式中文分词组件-word分词</p>

<p><a href="http://jena.apache.org/" rel="nofollow" data-token="17059f4d6d898c2c5ab4e16c1106f9f1">http://jena.apache.org/</a></p>

<p>jena是一个语义网络、知识图谱相关的软件。</p>



<h2 id="nlpchina"><a name="t19"></a>NLPchina</h2>

<p>NLPchina(中国自然语言处理开源组织)旗下有许多好用的工具。</p>

<p>官网：</p>

<p><a href="http://www.nlpcn.org/" rel="nofollow" data-token="4aff66b4c1df1f5fe0e522275ef36d8d">http://www.nlpcn.org/</a></p>

<p>Github：</p>

<p><a href="https://github.com/NLPchina" rel="nofollow" data-token="d83cbbaf87d19c11280a4792d999ccdc">https://github.com/NLPchina</a></p>



<h3 id="ansj"><a name="t20"></a>Ansj</h3>

<p>Ansj是一个NLPchina旗下的开源的Java中文分词工具，基于中科院的ictclas中文分词算法，比其他常用的开源分词工具（如mmseg4j）的分词准确率更高。</p>

<p><a href="https://github.com/NLPchina/ansj_seg" rel="nofollow" data-token="6f4d39911225d88423e3d2af42130f3f">https://github.com/NLPchina/ansj_seg</a></p>



<h3 id="word2vecjava"><a name="t21"></a>Word2VEC_java</h3>

<p>word2vec java版本的一个实现。</p>

<p><a href="https://github.com/NLPchina/Word2VEC_java" rel="nofollow" data-token="002a4fb23ae5fe246c09a25f1879bdd4">https://github.com/NLPchina/Word2VEC_java</a></p>

<p>doc2vec java版本的一个实现，基于Word2VEC_java。</p>

<p><a href="https://github.com/yao8839836/doc2vec_java" rel="nofollow" data-token="60793cdface8681d2e1a7f85f219e307">https://github.com/yao8839836/doc2vec_java</a></p>



<h3 id="ansjfastlda"><a name="t22"></a>ansj_fast_lda</h3>

<p>LDA算法的Java包。</p>

<p><a href="https://github.com/NLPchina/ansj_fast_lda" rel="nofollow" data-token="164549c5ca2837d2952b300543571837">https://github.com/NLPchina/ansj_fast_lda</a></p>



<h3 id="nlp-lang"><a name="t23"></a>nlp-lang</h3>

<p>这个项目是一个基本包.封装了大多数nlp项目中常用工具</p>

<p><a href="https://github.com/NLPchina/nlp-lang" rel="nofollow" data-token="8ce36aa690e0a2962e92bda7f4a18bae">https://github.com/NLPchina/nlp-lang</a></p>



<h2 id="词性标注"><a name="t24"></a>词性标注</h2>

<p><a href="http://jacoxu.com/ictpos3-0%E6%B1%89%E8%AF%AD%E8%AF%8D%E6%80%A7%E6%A0%87%E8%AE%B0%E9%9B%86/" rel="nofollow" data-token="e3745e7121b25f978c1ddb07244b3920">http://jacoxu.com/ictpos3-0%E6%B1%89%E8%AF%AD%E8%AF%8D%E6%80%A7%E6%A0%87%E8%AE%B0%E9%9B%86/</a></p>

<p>ICTPOS3.0汉语词性标记集</p>



<h2 id="word-hashing"><a name="t25"></a>Word Hashing</h2>

<p>Word Hashing是非常重要的一个trick，以英文单词来说，比如good，他可以写成<code>#good#</code>，然后按tri-grams来进行分解为<code>#go goo ood od#</code>，再将这个tri-grams灌入到bag-of-word中，这种方式可以非常有效的解决vocabulary太大的问题(因为在真实的web search中vocabulary就是异常的大)，另外也不会出现oov问题，因此英文单词才26个，3个字母的组合都是有限的，很容易枚举光。</p>

<p>那么问题就来了，这样两个不同的单词会不会产出相同的tri-grams，paper里面做了统计，说了这个冲突的概率非常的低，500K个word可以降到30k维，冲突的概率为0.0044%。</p>

<p>但是在中文场景下，这个Word Hashing估计没有这么有效了。</p>



<h2 id="词汇共现"><a name="t26"></a>词汇共现</h2>

<p>词汇共现是指词汇在文档集中共同出现。以一个词为中心，可以找到一组经常与之搭配出现的词，作为它的共现词汇集。</p>

<p>词汇共现的其中一种用例：</p>

<p>有若干关键词，比如：水果、天气、风，有若干描述词，比如，很甜、晴朗、很大，然后现在要找出他们之间的搭配，在这个例子里，我们最终要找到：水果很甜、天气晴朗、风很大</p>

<p><a href="http://sewm.pku.edu.cn/TianwangLiterature/SEWM/2005(5)/%5b%b3%c2%c1%88,%20et%20al.,2005%5d/050929.pdf" rel="nofollow" data-token="ad96761cada7cb422096004451b33f8d">http://sewm.pku.edu.cn/TianwangLiterature/SEWM/2005(5)/%5b%b3%c2%c1%88,%20et%20al.,2005%5d/050929.pdf</a></p>



<h2 id="关键词提取"><a name="t27"></a>关键词提取</h2>

<p>主要三种方法：</p>

<p>1.基于统计特征，如TF-IDF。</p>

<p>2.基于词图模型，如TextRank。</p>

<p>3.基于主题模型，如LDA。</p>



<h2 id="自然语言理解"><a name="t28"></a>自然语言理解</h2>

<p>Natural language understanding(NLU)属于NLP的一个分支，属于人工智能的一个部分，用来解决机器理解人类语言的问题，属于人工智能的核心难题。</p>

<p><img src="/images/article/domain_slot.png" alt="" title=""></p>

<p>上图是语义理解中，最有实用价值的框架语义表示（frame semantics representation）的原理简图。</p>

<p>参考：</p>

<p><a href="http://www.shuang0420.com/2017/04/27/NLP%E7%AC%94%E8%AE%B0%20-%20NLU%E4%B9%8B%E6%84%8F%E5%9B%BE%E5%88%86%E7%B1%BB/" rel="nofollow" data-token="847ab028e579cb9127e12b88cedb0728">http://www.shuang0420.com/2017/04/27/NLP%E7%AC%94%E8%AE%B0%20-%20NLU%E4%B9%8B%E6%84%8F%E5%9B%BE%E5%88%86%E7%B1%BB/</a></p>

<p>NLU之意图分类</p>



<h2 id="论文"><a name="t29"></a>论文</h2>

<p>《Distant Supervision for relation extraction without labeled data》</p>

<p>《Using Recurrent Neural Networks for Slot Filling in Spoken Language Understanding》</p>

<p>《Convolutional Neural Networks for Sentence Classification》：TextCNN的开山之作</p>



<h1 id="知识图谱参考资源"><a name="t30"></a>知识图谱参考资源</h1>

<p><a href="https://wenku.baidu.com/view/38ad3ef7e109581b6bd97f19227916888586b959.html" rel="nofollow" data-token="abb653c1994accfd0412c09953f29a35">https://wenku.baidu.com/view/38ad3ef7e109581b6bd97f19227916888586b959.html</a></p>

<p>知识图谱构建技术综述</p>

<p><a href="https://wenku.baidu.com/view/e69a3619fe00bed5b9f3f90f76c66137ee064f15.html" rel="nofollow" data-token="f62964fb34bc62388f8eca9233326ade">https://wenku.baidu.com/view/e69a3619fe00bed5b9f3f90f76c66137ee064f15.html</a></p>

<p>知识图谱技术综述</p>

<p><a href="https://wenku.baidu.com/view/b3858227c5da50e2534d7f08.html" rel="nofollow" data-token="a6ccab4c519f1591bcf5989046a98a1d">https://wenku.baidu.com/view/b3858227c5da50e2534d7f08.html</a></p>

<p>知识图谱技术原理介绍</p>

<p><a href="https://mp.weixin.qq.com/s/JLYegFP7kEg6n34crgP09g" rel="nofollow" data-token="38f83064d2747b29d35fc82a0e5398b2">https://mp.weixin.qq.com/s/JLYegFP7kEg6n34crgP09g</a></p>

<p>基于知识图谱的问答系统关键技术研究</p>

<p><a href="https://mp.weixin.qq.com/s/XgKvh63wgEe-CR9bchp03Q" rel="nofollow" data-token="cefb2d0a0d07e0e86cd576682056ddb0">https://mp.weixin.qq.com/s/XgKvh63wgEe-CR9bchp03Q</a></p>

<p>什么是知识图谱？</p>

<p><a href="https://mp.weixin.qq.com/s/iqFXvhvYfOejaeNAhXxJEg" rel="nofollow" data-token="1c1743a2bed9f126b702f85225ee77c0">https://mp.weixin.qq.com/s/iqFXvhvYfOejaeNAhXxJEg</a></p>

<p>当知识图谱遇上聊天机器人</p>

<p><a href="https://mp.weixin.qq.com/s/U-dlYhnaR8OQw2UKYKUWKQ" rel="nofollow" data-token="40c9b3f1c83fa9170c315fb703a46cfd">https://mp.weixin.qq.com/s/U-dlYhnaR8OQw2UKYKUWKQ</a></p>

<p>知识图谱前沿技术课程实录</p>

<p><a href="https://mp.weixin.qq.com/s/MZE_SXsNg6Yt4dz2fmB1sA" rel="nofollow" data-token="20f88e4b147dca9fdd18a561fd58c290">https://mp.weixin.qq.com/s/MZE_SXsNg6Yt4dz2fmB1sA</a></p>

<p>阿里知识图谱首次曝光：每天千万级拦截量，亿级别全量智能审核</p>

<p><a href="https://mp.weixin.qq.com/s/WIro7pk7kboMvdwpZOSdQA" rel="nofollow" data-token="c339d6da6a312ebcc6ce2d7032cb672a">https://mp.weixin.qq.com/s/WIro7pk7kboMvdwpZOSdQA</a></p>

<p>东南大学漆桂林：知识图谱的应用</p>

<p><a href="https://mp.weixin.qq.com/s/z1hhG4GaBQXPHHt9UGZPnA" rel="nofollow" data-token="1d5ee50ca19a148f72b9cd860a75505c">https://mp.weixin.qq.com/s/z1hhG4GaBQXPHHt9UGZPnA</a></p>

<p>东南大学高桓：知识图谱表示学习</p>

<p><a href="https://mp.weixin.qq.com/s/JZYH_m1eS93KRjkWA82GoA" rel="nofollow" data-token="e44ad4c8c56282bd482bea9f2f877377">https://mp.weixin.qq.com/s/JZYH_m1eS93KRjkWA82GoA</a></p>

<p>复旦肖仰华：基于知识图谱的问答系统</p>

<p><a href="https://mp.weixin.qq.com/s/cEmtOAtfP2gSBlaPfGXb3w" rel="nofollow" data-token="c4a243d4b626ca5df83cbaa36466409f">https://mp.weixin.qq.com/s/cEmtOAtfP2gSBlaPfGXb3w</a></p>

<p>多源信息表示学习在知识图谱中的应用</p>

<p><a href="https://mp.weixin.qq.com/s/cL1aKdu8ig8-ocOPirXk2w" rel="nofollow" data-token="2763f3a9ef93756e0a0293e118f0e3b3">https://mp.weixin.qq.com/s/cL1aKdu8ig8-ocOPirXk2w</a></p>

<p>如何构建知识图谱</p>

<p><a href="https://mp.weixin.qq.com/s/Nh7XJOLNBDdpibopVG4MrQ" rel="nofollow" data-token="7e1d1e19f467a2ef16cb10272b5da397">https://mp.weixin.qq.com/s/Nh7XJOLNBDdpibopVG4MrQ</a></p>

<p>中文通用百科知识图谱（CN-DBpedia）</p>                                    </div>

<br><br>
》》》机器学习与文本分析部分《《《
<br>
>第一期：深度学习与文本分析（CIPS ATT5）
第一讲：深度学习基础知识（邱锡鹏，复旦大学）

第一节 基础知识、前馈神经网络、分布式表示

第二节 卷积神经网络、循环神经网络、外部记忆与注意力模型

第三节 概率图模型、深度生成模型、深度强化学习

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/ATT2017-Basic.pdf




>第二讲：深度学习工具实战（龚经经，复旦大学）

第一节  TensorFlow介绍与深度学习模型实现

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/ATT2017-Practice.pdf



>第三讲：深度学习与词法句法语义分析 （车万翔，哈工大）

第一节   词法、句法与语义分析简介；结构化预测任务（序列分割、序列标注、句法分析）；传统的结构化预测方法（基于图方法、基于转移的方法）

第二节    基于神经网络的图方法；基于神经网络的转移方法

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/ATT2017-NLP.pdf



>第四讲：深度学习与知识获取 （刘康，中科院自动化所）

第一节   基于深度学习的词表示（NNLM、Word2Vector、Log-Bilinear等）、知识图谱表示学习（RESCAL、TransE、TransH、TransD、KG2E等）

第二节  基于深度学习的知识抽取：实体关系抽取、开放域关系抽取、事件抽取

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/ATT2017-Knowledge.pdf



>第二期：深度学习与NLP应用（CIPS ATT6）
第一讲：深度学习与机器翻译（熊德意，苏州大学）

第一节 神经机器翻译基础知识 ：神经机器翻译发展过程简介，串到串模型，基于注意力的神经机器翻译，注意力模型，集外词翻译，覆盖度模型，神经机器翻译与统计机器翻译比较与融合，神经机器翻译开源工具与平台

第二节 神经机器翻译进阶：字符与subword级神经机器翻译，基于句法的神经机器翻译与外部语言学知识融合，神经机器翻译新架构，多语与多模态神经机器翻译，神经机器翻译未来发展方向

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/ATT2017-NMT.pdf



>第二讲：深度学习与自动问答（冯岩松，北京大学）

第一节  自动问答简介；传统知识库问答；基于深度学习的知识问答 I

第二节  基于深度学习的知识问答 II；基于深度学习的阅读理解；基于深度学习的对话系统

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/ATT2017-QAI.pdf

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/QA_2017_QAII.pdf



>第三讲：深度学习与社会计算（赵鑫，中国人民大学信息学院）

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/ATT2017-IRII.pdf

第一节 网络表示：主要以network embedding作为主要技术点，包括一些基本的network embedding模型（包括DeepWalk、LINE、Node2vec等），同时也包括一些拓展工作（包括异质关系网络融合表示）

第二节 推荐系统：主要介绍最近几年深度学习在推荐系统中的应用，将分为两大块，刻画用户与物品交互以及刻画附加内容信息。将会涵盖大部分最新的深度学习推荐模型。

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/ATT2017-NetworkI.pdf



>第四讲：深度学习与信息检索（郭嘉丰，中科院计算所）

第一节 基于分布式表示的信息检索：深度学习搜索发展历史简介、分布式表达、基于分布式表达的信息检索模型及其在检索问题上的应用

第二节 基于深层匹配的信息检索：信息检索的深层匹配建模、深层匹配模型及其在不同检索问题上的应用，相关的Toolkit介绍

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/ATT2017-IRI.pdf

ppt：http://cips-upload.bj.bcebos.com/2017/ssatt2017/ATT2017-IRII.pdf


>[示例项目原文](http://www.52nlp.cn/%E6%AC%A2%E8%BF%8E%E5%85%B3%E6%B3%A8ainlp-%E4%B8%80%E4%B8%AA%E6%9C%89%E8%B6%A3%E6%9C%89ai%E7%9A%84nlp%E5%85%AC%E4%BC%97%E5%8F%B7)
<br>
[NLP教程原文](https://blog.csdn.net/antkillerfarm/article/details/78082564)
<br>
[机器学习与文本分析部分原文](https://mp.weixin.qq.com/s/5KhTWdOk-b84DXmoVr68-A)
